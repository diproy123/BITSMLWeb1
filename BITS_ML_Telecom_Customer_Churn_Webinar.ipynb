{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkNH3hsEpR-6",
        "outputId": "b6707157-3901-484f-e931-d33f779f6294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "CLASSIFICATION CASE STUDY: CUSTOMER CHURN PREDICTION\n",
            "Dataset: IBM Telco Customer Churn (Real Data)\n",
            "======================================================================\n",
            "\n",
            "[1] LOADING DATA...\n",
            "Attempting to download from: https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\n",
            "Successfully downloaded dataset!\n",
            "\n",
            "============================================================\n",
            "EXPLORATORY DATA ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Dataset Shape: (7043, 21)\n",
            "Total Customers: 7,043\n",
            "\n",
            "Column Names:\n",
            "['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
            "\n",
            "Data Types:\n",
            "customerID           object\n",
            "gender               object\n",
            "SeniorCitizen         int64\n",
            "Partner              object\n",
            "Dependents           object\n",
            "tenure                int64\n",
            "PhoneService         object\n",
            "MultipleLines        object\n",
            "InternetService      object\n",
            "OnlineSecurity       object\n",
            "OnlineBackup         object\n",
            "DeviceProtection     object\n",
            "TechSupport          object\n",
            "StreamingTV          object\n",
            "StreamingMovies      object\n",
            "Contract             object\n",
            "PaperlessBilling     object\n",
            "PaymentMethod        object\n",
            "MonthlyCharges      float64\n",
            "TotalCharges         object\n",
            "Churn                object\n",
            "dtype: object\n",
            "\n",
            "Missing Values:\n",
            "Series([], dtype: int64)\n",
            "\n",
            "Churn Distribution:\n",
            "Churn\n",
            "No     5174\n",
            "Yes    1869\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Churn Rate: 26.54%\n",
            "\n",
            "============================================================\n",
            "DATA PREPROCESSING\n",
            "============================================================\n",
            "Dropped customerID column\n",
            "Filled 11 missing TotalCharges values\n",
            "Converted Churn to binary (Yes=1, No=0)\n",
            "\n",
            "Encoding 15 categorical columns:\n",
            "  - gender: 2 unique values\n",
            "  - Partner: 2 unique values\n",
            "  - Dependents: 2 unique values\n",
            "  - PhoneService: 2 unique values\n",
            "  - MultipleLines: 3 unique values\n",
            "  - InternetService: 3 unique values\n",
            "  - OnlineSecurity: 3 unique values\n",
            "  - OnlineBackup: 3 unique values\n",
            "  - DeviceProtection: 3 unique values\n",
            "  - TechSupport: 3 unique values\n",
            "  - StreamingTV: 3 unique values\n",
            "  - StreamingMovies: 3 unique values\n",
            "  - Contract: 3 unique values\n",
            "  - PaperlessBilling: 2 unique values\n",
            "  - PaymentMethod: 4 unique values\n",
            "\n",
            "Final dataset shape: (7043, 20)\n",
            "\n",
            "Training set: 5,634 samples\n",
            "Test set: 1,409 samples\n",
            "Features: 19\n",
            "\n",
            "[2] TRAINING MODELS...\n",
            "\n",
            "============================================================\n",
            "LOGISTIC REGRESSION\n",
            "============================================================\n",
            "\n",
            "Accuracy: 0.7991\n",
            "Precision: 0.6426\n",
            "Recall: 0.5481\n",
            "F1 Score: 0.5916\n",
            "\n",
            "============================================================\n",
            "DECISION TREE\n",
            "============================================================\n",
            "\n",
            "Best Parameters: {'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 2}\n",
            "\n",
            "Accuracy: 0.7814\n",
            "Precision: 0.5988\n",
            "Recall: 0.5348\n",
            "F1 Score: 0.5650\n",
            "\n",
            "Top 5 Feature Importance:\n",
            "           feature  importance\n",
            "14        Contract    0.452479\n",
            "8   OnlineSecurity    0.119518\n",
            "4           tenure    0.095790\n",
            "17  MonthlyCharges    0.095780\n",
            "18    TotalCharges    0.086369\n",
            "\n",
            "============================================================\n",
            "K-NEAREST NEIGHBORS (KNN)\n",
            "============================================================\n",
            "\n",
            "Searching for optimal K...\n",
            "Optimal K: 23\n",
            "\n",
            "Accuracy: 0.7679\n",
            "Precision: 0.5673\n",
            "Recall: 0.5294\n",
            "F1 Score: 0.5477\n",
            "\n",
            "============================================================\n",
            "SUPPORT VECTOR MACHINE (SVM)\n",
            "============================================================\n",
            "\n",
            "Training linear kernel...\n",
            "  LINEAR - Accuracy: 0.7878, F1: 0.5660\n",
            "\n",
            "Training rbf kernel...\n",
            "  RBF - Accuracy: 0.7935, F1: 0.5516\n",
            "\n",
            "Training poly kernel...\n",
            "  POLY - Accuracy: 0.7857, F1: 0.5311\n",
            "\n",
            "Best Kernel: linear\n",
            "\n",
            "Final Results (linear):\n",
            "Accuracy: 0.7878\n",
            "Precision: 0.6190\n",
            "Recall: 0.5214\n",
            "F1 Score: 0.5660\n",
            "\n",
            "============================================================\n",
            "ENSEMBLE LEARNING\n",
            "============================================================\n",
            "\n",
            "--- Random Forest ---\n",
            "Accuracy: 0.7999\n",
            "F1 Score: 0.5766\n",
            "\n",
            "--- Gradient Boosting ---\n",
            "Accuracy: 0.7949\n",
            "F1 Score: 0.5706\n",
            "\n",
            "--- AdaBoost ---\n",
            "Accuracy: 0.7977\n",
            "F1 Score: 0.5852\n",
            "\n",
            "--- Bagging Classifier ---\n",
            "Accuracy: 0.7722\n",
            "F1 Score: 0.5258\n",
            "\n",
            "--- Voting Classifier (Soft Voting) ---\n",
            "Accuracy: 0.8020\n",
            "F1 Score: 0.5805\n",
            "\n",
            "[3] GENERATING VISUALIZATIONS...\n",
            "Saved: confusion_matrices.png\n",
            "Saved: roc_curves.png\n",
            "Saved: pr_curves.png\n",
            "Saved: model_comparison.png\n",
            "Saved: knn_optimization.png\n",
            "Saved: rf_feature_importance.png\n",
            "Saved: gb_feature_importance.png\n",
            "\n",
            "[4] FINAL SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Model Performance Summary:\n",
            "                     Accuracy  Precision  Recall  F1 Score\n",
            "Model                                                     \n",
            "Logistic Regression    0.7991     0.6426  0.5481    0.5916\n",
            "Decision Tree          0.7814     0.5988  0.5348    0.5650\n",
            "KNN                    0.7679     0.5673  0.5294    0.5477\n",
            "SVM                    0.7878     0.6190  0.5214    0.5660\n",
            "Random Forest          0.7999     0.6575  0.5134    0.5766\n",
            "Gradient Boosting      0.7949     0.6421  0.5134    0.5706\n",
            "AdaBoost               0.7977     0.6422  0.5374    0.5852\n",
            "Bagging                0.7722     0.5875  0.4759    0.5258\n",
            "Voting Classifier      0.8020     0.6632  0.5160    0.5805\n",
            "\n",
            "ðŸ† Best Performing Model (by F1 Score): Logistic Regression\n",
            "   F1 Score: 0.5916\n",
            "   Accuracy: 0.7991\n",
            "\n",
            "Summary saved to: model_comparison_summary.csv\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Classification Case Study: Customer Churn Prediction\n",
        "=====================================================\n",
        "A comprehensive webinar demonstrating various classification algorithms:\n",
        "- Logistic Regression\n",
        "- Decision Tree\n",
        "- K-Nearest Neighbors (KNN)\n",
        "- Support Vector Machine (SVM)\n",
        "- Instance-Based Learning\n",
        "- Ensemble Methods (Random Forest, Gradient Boosting, Voting Classifier)\n",
        "\n",
        "Dataset: IBM Telco Customer Churn (Real Dataset)\n",
        "Download from: https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\n",
        "\n",
        "Or use: https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    VotingClassifier,\n",
        "    AdaBoostClassifier,\n",
        "    BaggingClassifier\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_curve, auc,\n",
        "    precision_recall_curve, average_precision_score\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for visualizations\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 1: DATA LOADING AND PREPARATION\n",
        "# =============================================================================\n",
        "\n",
        "def load_telco_data(filepath=None):\n",
        "    \"\"\"\n",
        "    Load the IBM Telco Customer Churn dataset.\n",
        "\n",
        "    If filepath is provided, loads from local file.\n",
        "    Otherwise, attempts to download from GitHub.\n",
        "\n",
        "    Download the dataset manually from:\n",
        "    https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\n",
        "\n",
        "    Or from Kaggle:\n",
        "    https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
        "    \"\"\"\n",
        "    if filepath:\n",
        "        print(f\"Loading data from: {filepath}\")\n",
        "        df = pd.read_csv(filepath)\n",
        "    else:\n",
        "        # Try to download from GitHub\n",
        "        url = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
        "        try:\n",
        "            print(f\"Attempting to download from: {url}\")\n",
        "            df = pd.read_csv(url)\n",
        "            print(\"Successfully downloaded dataset!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not download dataset: {e}\")\n",
        "            print(\"\\nPlease download the dataset manually from:\")\n",
        "            print(\"https://www.kaggle.com/datasets/blastchar/telco-customer-churn\")\n",
        "            print(\"\\nOr use the direct GitHub link:\")\n",
        "            print(\"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\")\n",
        "            print(\"\\nThen run: load_telco_data('path/to/Telco-Customer-Churn.csv')\")\n",
        "            return None\n",
        "\n",
        "    return df\n",
        "\n",
        "def explore_data(df):\n",
        "    \"\"\"\n",
        "    Perform exploratory data analysis on the dataset.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"\\nDataset Shape: {df.shape}\")\n",
        "    print(f\"Total Customers: {len(df):,}\")\n",
        "\n",
        "    print(\"\\nColumn Names:\")\n",
        "    print(df.columns.tolist())\n",
        "\n",
        "    print(\"\\nData Types:\")\n",
        "    print(df.dtypes)\n",
        "\n",
        "    print(\"\\nMissing Values:\")\n",
        "    print(df.isnull().sum()[df.isnull().sum() > 0])\n",
        "\n",
        "    print(\"\\nChurn Distribution:\")\n",
        "    print(df['Churn'].value_counts())\n",
        "    print(f\"\\nChurn Rate: {df['Churn'].value_counts(normalize=True).get('Yes', df['Churn'].value_counts(normalize=True).get(1, 0)):.2%}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def preprocess_telco_data(df):\n",
        "    \"\"\"\n",
        "    Preprocess the IBM Telco Customer Churn dataset.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DATA PREPROCESSING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Drop customerID (not useful for prediction)\n",
        "    if 'customerID' in df_processed.columns:\n",
        "        df_processed = df_processed.drop('customerID', axis=1)\n",
        "        print(\"Dropped customerID column\")\n",
        "\n",
        "    # Handle TotalCharges - convert to numeric and handle missing/empty values\n",
        "    if 'TotalCharges' in df_processed.columns:\n",
        "        df_processed['TotalCharges'] = pd.to_numeric(df_processed['TotalCharges'], errors='coerce')\n",
        "        # Fill missing TotalCharges with tenure * MonthlyCharges\n",
        "        mask = df_processed['TotalCharges'].isnull()\n",
        "        if mask.any():\n",
        "            df_processed.loc[mask, 'TotalCharges'] = df_processed.loc[mask, 'tenure'] * df_processed.loc[mask, 'MonthlyCharges']\n",
        "            print(f\"Filled {mask.sum()} missing TotalCharges values\")\n",
        "\n",
        "    # Convert Churn to binary\n",
        "    if df_processed['Churn'].dtype == 'object':\n",
        "        df_processed['Churn'] = (df_processed['Churn'] == 'Yes').astype(int)\n",
        "        print(\"Converted Churn to binary (Yes=1, No=0)\")\n",
        "\n",
        "    # Encode categorical variables\n",
        "    label_encoders = {}\n",
        "    categorical_cols = df_processed.select_dtypes(include=['object']).columns\n",
        "\n",
        "    print(f\"\\nEncoding {len(categorical_cols)} categorical columns:\")\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "        print(f\"  - {col}: {len(le.classes_)} unique values\")\n",
        "\n",
        "    # Check for any remaining missing values\n",
        "    if df_processed.isnull().sum().sum() > 0:\n",
        "        print(\"\\nDropping rows with remaining missing values...\")\n",
        "        df_processed = df_processed.dropna()\n",
        "\n",
        "    print(f\"\\nFinal dataset shape: {df_processed.shape}\")\n",
        "\n",
        "    return df_processed, label_encoders\n",
        "\n",
        "def prepare_data_splits(df_processed, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Split data into training and testing sets.\n",
        "    \"\"\"\n",
        "    X = df_processed.drop('Churn', axis=1)\n",
        "    y = df_processed['Churn']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    print(f\"\\nTraining set: {len(X_train):,} samples\")\n",
        "    print(f\"Test set: {len(X_test):,} samples\")\n",
        "    print(f\"Features: {X_train.shape[1]}\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, scaler\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 2: MODEL IMPLEMENTATIONS\n",
        "# =============================================================================\n",
        "\n",
        "def train_logistic_regression(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Train and evaluate Logistic Regression model.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"LOGISTIC REGRESSION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Model with regularization tuning\n",
        "    lr = LogisticRegression(random_state=42, max_iter=1000, C=0.5)\n",
        "    lr.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = lr.predict(X_test)\n",
        "    y_prob = lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Evaluation\n",
        "    print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "    # Feature importance (coefficients)\n",
        "    if hasattr(X_train, 'columns'):\n",
        "        print(\"\\nTop 5 Feature Coefficients (by absolute value):\")\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': X_train.columns,\n",
        "            'coefficient': lr.coef_[0]\n",
        "        }).sort_values('coefficient', key=abs, ascending=False)\n",
        "        print(feature_importance.head())\n",
        "\n",
        "    return lr, y_pred, y_prob\n",
        "\n",
        "def train_decision_tree(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Train and evaluate Decision Tree model with hyperparameter tuning.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DECISION TREE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    param_grid = {\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_samples_split': [2, 5, 10, 20],\n",
        "        'min_samples_leaf': [1, 2, 4, 8]\n",
        "    }\n",
        "\n",
        "    dt = DecisionTreeClassifier(random_state=42)\n",
        "    grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_dt = grid_search.best_estimator_\n",
        "    print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = best_dt.predict(X_test)\n",
        "    y_prob = best_dt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Evaluation\n",
        "    print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "    # Feature importance\n",
        "    if hasattr(X_train, 'columns'):\n",
        "        print(\"\\nTop 5 Feature Importance:\")\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': X_train.columns,\n",
        "            'importance': best_dt.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "        print(feature_importance.head())\n",
        "\n",
        "    return best_dt, y_pred, y_prob\n",
        "\n",
        "def train_knn(X_train_scaled, y_train, X_test_scaled, y_test):\n",
        "    \"\"\"\n",
        "    Train and evaluate K-Nearest Neighbors model.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"K-NEAREST NEIGHBORS (KNN)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Find optimal K (odd numbers from 3 to 29 to avoid ties)\n",
        "    k_range = range(3, 30, 2)\n",
        "    cv_scores = []\n",
        "\n",
        "    print(\"\\nSearching for optimal K...\")\n",
        "    for k in k_range:\n",
        "        knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
        "        scores = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='f1')\n",
        "        cv_scores.append(scores.mean())\n",
        "\n",
        "    best_k = list(k_range)[np.argmax(cv_scores)]\n",
        "    print(f\"Optimal K: {best_k}\")\n",
        "\n",
        "    # Train with best K\n",
        "    knn = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = knn.predict(X_test_scaled)\n",
        "    y_prob = knn.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # Evaluation\n",
        "    print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "    return knn, y_pred, y_prob, k_range, cv_scores\n",
        "\n",
        "def train_svm(X_train_scaled, y_train, X_test_scaled, y_test):\n",
        "    \"\"\"\n",
        "    Train and evaluate Support Vector Machine model.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SUPPORT VECTOR MACHINE (SVM)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Train with different kernels\n",
        "    kernels = ['linear', 'rbf', 'poly']\n",
        "    results = {}\n",
        "\n",
        "    for kernel in kernels:\n",
        "        print(f\"\\nTraining {kernel} kernel...\")\n",
        "        svm = SVC(kernel=kernel, probability=True, random_state=42, C=1.0)\n",
        "        svm.fit(X_train_scaled, y_train)\n",
        "        y_pred = svm.predict(X_test_scaled)\n",
        "        results[kernel] = {\n",
        "            'model': svm,\n",
        "            'accuracy': accuracy_score(y_test, y_pred),\n",
        "            'f1': f1_score(y_test, y_pred)\n",
        "        }\n",
        "        print(f\"  {kernel.upper()} - Accuracy: {results[kernel]['accuracy']:.4f}, F1: {results[kernel]['f1']:.4f}\")\n",
        "\n",
        "    # Select best kernel\n",
        "    best_kernel = max(results.keys(), key=lambda k: results[k]['f1'])\n",
        "    best_svm = results[best_kernel]['model']\n",
        "\n",
        "    print(f\"\\nBest Kernel: {best_kernel}\")\n",
        "\n",
        "    # Final predictions with best model\n",
        "    y_pred = best_svm.predict(X_test_scaled)\n",
        "    y_prob = best_svm.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    print(f\"\\nFinal Results ({best_kernel}):\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "    return best_svm, y_pred, y_prob, results\n",
        "\n",
        "def train_ensemble_models(X_train, y_train, X_test, y_test, X_train_scaled, X_test_scaled):\n",
        "    \"\"\"\n",
        "    Train and evaluate Ensemble Learning models.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ENSEMBLE LEARNING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    ensemble_results = {}\n",
        "\n",
        "    # 1. Random Forest\n",
        "    print(\"\\n--- Random Forest ---\")\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred_rf = rf.predict(X_test)\n",
        "    y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
        "    ensemble_results['Random Forest'] = {\n",
        "        'model': rf,\n",
        "        'y_pred': y_pred_rf,\n",
        "        'y_prob': y_prob_rf,\n",
        "        'accuracy': accuracy_score(y_test, y_pred_rf),\n",
        "        'f1': f1_score(y_test, y_pred_rf)\n",
        "    }\n",
        "    print(f\"Accuracy: {ensemble_results['Random Forest']['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {ensemble_results['Random Forest']['f1']:.4f}\")\n",
        "\n",
        "    # 2. Gradient Boosting\n",
        "    print(\"\\n--- Gradient Boosting ---\")\n",
        "    gb = GradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "    gb.fit(X_train, y_train)\n",
        "    y_pred_gb = gb.predict(X_test)\n",
        "    y_prob_gb = gb.predict_proba(X_test)[:, 1]\n",
        "    ensemble_results['Gradient Boosting'] = {\n",
        "        'model': gb,\n",
        "        'y_pred': y_pred_gb,\n",
        "        'y_prob': y_prob_gb,\n",
        "        'accuracy': accuracy_score(y_test, y_pred_gb),\n",
        "        'f1': f1_score(y_test, y_pred_gb)\n",
        "    }\n",
        "    print(f\"Accuracy: {ensemble_results['Gradient Boosting']['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {ensemble_results['Gradient Boosting']['f1']:.4f}\")\n",
        "\n",
        "    # 3. AdaBoost\n",
        "    print(\"\\n--- AdaBoost ---\")\n",
        "    ada = AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=42)\n",
        "    ada.fit(X_train, y_train)\n",
        "    y_pred_ada = ada.predict(X_test)\n",
        "    y_prob_ada = ada.predict_proba(X_test)[:, 1]\n",
        "    ensemble_results['AdaBoost'] = {\n",
        "        'model': ada,\n",
        "        'y_pred': y_pred_ada,\n",
        "        'y_prob': y_prob_ada,\n",
        "        'accuracy': accuracy_score(y_test, y_pred_ada),\n",
        "        'f1': f1_score(y_test, y_pred_ada)\n",
        "    }\n",
        "    print(f\"Accuracy: {ensemble_results['AdaBoost']['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {ensemble_results['AdaBoost']['f1']:.4f}\")\n",
        "\n",
        "    # 4. Bagging Classifier\n",
        "    print(\"\\n--- Bagging Classifier ---\")\n",
        "    bagging = BaggingClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
        "    bagging.fit(X_train, y_train)\n",
        "    y_pred_bag = bagging.predict(X_test)\n",
        "    y_prob_bag = bagging.predict_proba(X_test)[:, 1]\n",
        "    ensemble_results['Bagging'] = {\n",
        "        'model': bagging,\n",
        "        'y_pred': y_pred_bag,\n",
        "        'y_prob': y_prob_bag,\n",
        "        'accuracy': accuracy_score(y_test, y_pred_bag),\n",
        "        'f1': f1_score(y_test, y_pred_bag)\n",
        "    }\n",
        "    print(f\"Accuracy: {ensemble_results['Bagging']['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {ensemble_results['Bagging']['f1']:.4f}\")\n",
        "\n",
        "    # 5. Voting Classifier\n",
        "    print(\"\\n--- Voting Classifier (Soft Voting) ---\")\n",
        "    voting_clf = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
        "            ('rf', RandomForestClassifier(n_estimators=50, max_depth=8, random_state=42)),\n",
        "            ('gb', GradientBoostingClassifier(n_estimators=50, max_depth=4, random_state=42))\n",
        "        ],\n",
        "        voting='soft'\n",
        "    )\n",
        "    voting_clf.fit(X_train, y_train)\n",
        "    y_pred_vote = voting_clf.predict(X_test)\n",
        "    y_prob_vote = voting_clf.predict_proba(X_test)[:, 1]\n",
        "    ensemble_results['Voting Classifier'] = {\n",
        "        'model': voting_clf,\n",
        "        'y_pred': y_pred_vote,\n",
        "        'y_prob': y_prob_vote,\n",
        "        'accuracy': accuracy_score(y_test, y_pred_vote),\n",
        "        'f1': f1_score(y_test, y_pred_vote)\n",
        "    }\n",
        "    print(f\"Accuracy: {ensemble_results['Voting Classifier']['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {ensemble_results['Voting Classifier']['f1']:.4f}\")\n",
        "\n",
        "    return ensemble_results\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 3: EVALUATION & VISUALIZATION\n",
        "# =============================================================================\n",
        "\n",
        "def plot_confusion_matrices(y_test, predictions_dict, save_path='confusion_matrices.png'):\n",
        "    \"\"\"Plot confusion matrices for all models.\"\"\"\n",
        "    n_models = len(predictions_dict)\n",
        "    n_cols = 3\n",
        "    n_rows = (n_models + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 4*n_rows))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for idx, (name, y_pred) in enumerate(predictions_dict.items()):\n",
        "        if idx < len(axes):\n",
        "            cm = confusion_matrix(y_test, y_pred)\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
        "                       xticklabels=['No Churn', 'Churn'],\n",
        "                       yticklabels=['No Churn', 'Churn'])\n",
        "            axes[idx].set_title(f'{name}', fontsize=11, fontweight='bold')\n",
        "            axes[idx].set_xlabel('Predicted')\n",
        "            axes[idx].set_ylabel('Actual')\n",
        "\n",
        "    for idx in range(n_models, len(axes)):\n",
        "        axes[idx].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved: {save_path}\")\n",
        "\n",
        "def plot_roc_curves(y_test, probabilities_dict, save_path='roc_curves.png'):\n",
        "    \"\"\"Plot ROC curves for all models.\"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(probabilities_dict)))\n",
        "\n",
        "    for (name, y_prob), color in zip(probabilities_dict.items(), colors):\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, color=color, lw=2, label=f'{name} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate', fontsize=12)\n",
        "    plt.title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc='lower right', fontsize=9)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved: {save_path}\")\n",
        "\n",
        "def plot_precision_recall_curves(y_test, probabilities_dict, save_path='pr_curves.png'):\n",
        "    \"\"\"Plot Precision-Recall curves for all models.\"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(probabilities_dict)))\n",
        "\n",
        "    for (name, y_prob), color in zip(probabilities_dict.items(), colors):\n",
        "        precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "        avg_precision = average_precision_score(y_test, y_prob)\n",
        "        plt.plot(recall, precision, color=color, lw=2,\n",
        "                label=f'{name} (AP = {avg_precision:.3f})')\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Recall', fontsize=12)\n",
        "    plt.ylabel('Precision', fontsize=12)\n",
        "    plt.title('Precision-Recall Curves Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc='lower left', fontsize=9)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved: {save_path}\")\n",
        "\n",
        "def plot_model_comparison(metrics_dict, save_path='model_comparison.png'):\n",
        "    \"\"\"Create a bar chart comparing all models across metrics.\"\"\"\n",
        "    metrics_df = pd.DataFrame(metrics_dict).T\n",
        "\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
        "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "    colors = ['#3498db', '#2ecc71', '#e74c3c', '#9b59b6']\n",
        "\n",
        "    for idx, (metric, color) in enumerate(zip(metrics, colors)):\n",
        "        values = metrics_df[metric].sort_values(ascending=True)\n",
        "        axes[idx].barh(values.index, values.values, color=color, alpha=0.8)\n",
        "        axes[idx].set_xlabel(metric, fontsize=11)\n",
        "        axes[idx].set_xlim([0.4, 1.0])\n",
        "        axes[idx].set_title(metric, fontsize=12, fontweight='bold')\n",
        "        for i, v in enumerate(values.values):\n",
        "            axes[idx].text(v + 0.01, i, f'{v:.3f}', va='center', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved: {save_path}\")\n",
        "\n",
        "def plot_knn_optimization(k_range, cv_scores, save_path='knn_optimization.png'):\n",
        "    \"\"\"Plot KNN optimization curve showing optimal K value.\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    k_list = list(k_range)\n",
        "    plt.plot(k_list, cv_scores, 'b-o', linewidth=2, markersize=6)\n",
        "    plt.fill_between(k_list, cv_scores, alpha=0.2)\n",
        "\n",
        "    best_k = k_list[np.argmax(cv_scores)]\n",
        "    best_score = max(cv_scores)\n",
        "    plt.axvline(x=best_k, color='r', linestyle='--', label=f'Optimal K = {best_k}')\n",
        "    plt.scatter([best_k], [best_score], color='red', s=150, zorder=5, marker='*')\n",
        "\n",
        "    plt.xlabel('Number of Neighbors (K)', fontsize=12)\n",
        "    plt.ylabel('Cross-Validation F1 Score', fontsize=12)\n",
        "    plt.title('KNN Hyperparameter Optimization', fontsize=14, fontweight='bold')\n",
        "    plt.legend(fontsize=11)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved: {save_path}\")\n",
        "\n",
        "def plot_feature_importance(model, feature_names, title, save_path):\n",
        "    \"\"\"Plot feature importance for tree-based models.\"\"\"\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        importance = model.feature_importances_\n",
        "    elif hasattr(model, 'coef_'):\n",
        "        importance = np.abs(model.coef_[0])\n",
        "    else:\n",
        "        return\n",
        "\n",
        "    feature_imp = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': importance\n",
        "    }).sort_values('importance', ascending=True).tail(10)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(feature_imp['feature'], feature_imp['importance'], color='#3498db', alpha=0.8)\n",
        "    plt.xlabel('Importance', fontsize=12)\n",
        "    plt.title(f'{title} - Top 10 Features', fontsize=14, fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3, axis='x')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved: {save_path}\")\n",
        "\n",
        "def create_summary_table(metrics_dict):\n",
        "    \"\"\"Create a summary table of all model metrics.\"\"\"\n",
        "    df = pd.DataFrame(metrics_dict).T\n",
        "    df = df.round(4)\n",
        "    df.index.name = 'Model'\n",
        "    return df\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 4: MAIN EXECUTION\n",
        "# =============================================================================\n",
        "\n",
        "def main(data_path=None):\n",
        "    \"\"\"\n",
        "    Main function to run the complete classification case study.\n",
        "\n",
        "    Args:\n",
        "        data_path: Path to the Telco-Customer-Churn.csv file.\n",
        "                   If None, will attempt to download from GitHub.\n",
        "    \"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"CLASSIFICATION CASE STUDY: CUSTOMER CHURN PREDICTION\")\n",
        "    print(\"Dataset: IBM Telco Customer Churn (Real Data)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # 1. Load data\n",
        "    print(\"\\n[1] LOADING DATA...\")\n",
        "    df = load_telco_data(data_path)\n",
        "\n",
        "    if df is None:\n",
        "        print(\"\\nERROR: Could not load dataset. Please provide a valid path.\")\n",
        "        return None\n",
        "\n",
        "    # 2. Explore data\n",
        "    df = explore_data(df)\n",
        "\n",
        "    # 3. Preprocess data\n",
        "    df_processed, label_encoders = preprocess_telco_data(df)\n",
        "    X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, scaler = prepare_data_splits(df_processed)\n",
        "\n",
        "    feature_names = X_train.columns.tolist()\n",
        "\n",
        "    # Store all predictions and probabilities\n",
        "    all_predictions = {}\n",
        "    all_probabilities = {}\n",
        "    all_metrics = {}\n",
        "\n",
        "    # 4. Train models\n",
        "    print(\"\\n[2] TRAINING MODELS...\")\n",
        "\n",
        "    # Logistic Regression\n",
        "    lr_model, lr_pred, lr_prob = train_logistic_regression(X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "    all_predictions['Logistic Regression'] = lr_pred\n",
        "    all_probabilities['Logistic Regression'] = lr_prob\n",
        "    all_metrics['Logistic Regression'] = {\n",
        "        'Accuracy': accuracy_score(y_test, lr_pred),\n",
        "        'Precision': precision_score(y_test, lr_pred),\n",
        "        'Recall': recall_score(y_test, lr_pred),\n",
        "        'F1 Score': f1_score(y_test, lr_pred)\n",
        "    }\n",
        "\n",
        "    # Decision Tree\n",
        "    dt_model, dt_pred, dt_prob = train_decision_tree(X_train, y_train, X_test, y_test)\n",
        "    all_predictions['Decision Tree'] = dt_pred\n",
        "    all_probabilities['Decision Tree'] = dt_prob\n",
        "    all_metrics['Decision Tree'] = {\n",
        "        'Accuracy': accuracy_score(y_test, dt_pred),\n",
        "        'Precision': precision_score(y_test, dt_pred),\n",
        "        'Recall': recall_score(y_test, dt_pred),\n",
        "        'F1 Score': f1_score(y_test, dt_pred)\n",
        "    }\n",
        "\n",
        "    # KNN\n",
        "    knn_model, knn_pred, knn_prob, k_range, cv_scores = train_knn(X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "    all_predictions['KNN'] = knn_pred\n",
        "    all_probabilities['KNN'] = knn_prob\n",
        "    all_metrics['KNN'] = {\n",
        "        'Accuracy': accuracy_score(y_test, knn_pred),\n",
        "        'Precision': precision_score(y_test, knn_pred),\n",
        "        'Recall': recall_score(y_test, knn_pred),\n",
        "        'F1 Score': f1_score(y_test, knn_pred)\n",
        "    }\n",
        "\n",
        "    # SVM\n",
        "    svm_model, svm_pred, svm_prob, svm_results = train_svm(X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "    all_predictions['SVM'] = svm_pred\n",
        "    all_probabilities['SVM'] = svm_prob\n",
        "    all_metrics['SVM'] = {\n",
        "        'Accuracy': accuracy_score(y_test, svm_pred),\n",
        "        'Precision': precision_score(y_test, svm_pred),\n",
        "        'Recall': recall_score(y_test, svm_pred),\n",
        "        'F1 Score': f1_score(y_test, svm_pred)\n",
        "    }\n",
        "\n",
        "    # Ensemble Methods\n",
        "    ensemble_results = train_ensemble_models(X_train, y_train, X_test, y_test, X_train_scaled, X_test_scaled)\n",
        "\n",
        "    for name, results in ensemble_results.items():\n",
        "        all_predictions[name] = results['y_pred']\n",
        "        all_probabilities[name] = results['y_prob']\n",
        "        all_metrics[name] = {\n",
        "            'Accuracy': accuracy_score(y_test, results['y_pred']),\n",
        "            'Precision': precision_score(y_test, results['y_pred']),\n",
        "            'Recall': recall_score(y_test, results['y_pred']),\n",
        "            'F1 Score': f1_score(y_test, results['y_pred'])\n",
        "        }\n",
        "\n",
        "    # 5. Generate visualizations\n",
        "    print(\"\\n[3] GENERATING VISUALIZATIONS...\")\n",
        "\n",
        "    plot_confusion_matrices(y_test, all_predictions)\n",
        "    plot_roc_curves(y_test, all_probabilities)\n",
        "    plot_precision_recall_curves(y_test, all_probabilities)\n",
        "    plot_model_comparison(all_metrics)\n",
        "    plot_knn_optimization(k_range, cv_scores)\n",
        "    plot_feature_importance(ensemble_results['Random Forest']['model'], feature_names,\n",
        "                           'Random Forest', 'rf_feature_importance.png')\n",
        "    plot_feature_importance(ensemble_results['Gradient Boosting']['model'], feature_names,\n",
        "                           'Gradient Boosting', 'gb_feature_importance.png')\n",
        "\n",
        "    # 6. Create summary\n",
        "    print(\"\\n[4] FINAL SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    summary_df = create_summary_table(all_metrics)\n",
        "    print(\"\\nModel Performance Summary:\")\n",
        "    print(summary_df.to_string())\n",
        "\n",
        "    # Best model\n",
        "    best_model = summary_df['F1 Score'].idxmax()\n",
        "    print(f\"\\nðŸ† Best Performing Model (by F1 Score): {best_model}\")\n",
        "    print(f\"   F1 Score: {summary_df.loc[best_model, 'F1 Score']:.4f}\")\n",
        "    print(f\"   Accuracy: {summary_df.loc[best_model, 'Accuracy']:.4f}\")\n",
        "\n",
        "    # Save summary to CSV\n",
        "    summary_df.to_csv('model_comparison_summary.csv')\n",
        "    print(\"\\nSummary saved to: model_comparison_summary.csv\")\n",
        "\n",
        "    return {\n",
        "        'models': {\n",
        "            'logistic_regression': lr_model,\n",
        "            'decision_tree': dt_model,\n",
        "            'knn': knn_model,\n",
        "            'svm': svm_model,\n",
        "            'ensemble': ensemble_results\n",
        "        },\n",
        "        'predictions': all_predictions,\n",
        "        'probabilities': all_probabilities,\n",
        "        'metrics': all_metrics,\n",
        "        'summary': summary_df\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Option 1: Download automatically (requires internet access)\n",
        "    # results = main()\n",
        "\n",
        "    # Option 2: Use local file (recommended)\n",
        "    # Download the dataset from:\n",
        "    # https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\n",
        "    # Then run:\n",
        "    # results = main('Telco-Customer-Churn.csv')\n",
        "\n",
        "    # Try automatic download first, fall back to instructions\n",
        "    results = main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y_wvMmzqr4P1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}